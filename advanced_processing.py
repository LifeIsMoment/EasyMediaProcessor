import cv2
import numpy as np
from pathlib import Path
from PySide6.QtCore import QThread, Signal
from PySide6.QtWidgets import (QDialog, QVBoxLayout, QHBoxLayout, QPushButton, 
                              QLabel, QGroupBox, QComboBox, QSpinBox, 
                              QSlider, QGridLayout, QProgressBar, QTextEdit,
                              QFileDialog, QCheckBox, QTabWidget, QWidget,
                              QMessageBox)
from PySide6.QtCore import Qt
from PIL import Image, ImageEnhance, ImageFilter
import matplotlib.pyplot as plt
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure

class AdvancedProcessor(QThread):
    """ê³ ê¸‰ ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì²˜ë¦¬ ìŠ¤ë ˆë“œ"""
    progress = Signal(int)
    result = Signal(str, str)  # message, output_path
    error = Signal(str)
    
    def __init__(self, input_path, output_path, operation, parameters):
        super().__init__()
        self.input_path = input_path
        self.output_path = output_path
        self.operation = operation
        self.parameters = parameters
    
    def run(self):
        try:
            if self.operation == "channel_split":
                self.split_color_channels()
            elif self.operation == "domain_convert":
                self.convert_color_domain()
            elif self.operation == "histogram":
                self.generate_histogram()
            elif self.operation == "enhance":
                self.enhance_image()
            elif self.operation == "filter":
                self.apply_filter()
            elif self.operation == "crop_video":
                self.crop_video()
            elif self.operation == "upscale":
                self.upscale_image()
            elif self.operation == "noise_reduction":
                self.reduce_noise()
            else:
                self.error.emit(f"ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—…: {self.operation}")
        except Exception as e:
            self.error.emit(f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    def split_color_channels(self):
        """RGB/HSV ì±„ë„ ë¶„ë¦¬"""
        self.progress.emit(10)
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(self.input_path)
        if image is None:
            raise ValueError("ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        color_space = self.parameters.get('color_space', 'RGB')
        
        if color_space == 'RGB':
            # BGR to RGB
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            channels = cv2.split(image_rgb)
            channel_names = ['Red', 'Green', 'Blue']
        elif color_space == 'HSV':
            # BGR to HSV
            image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            channels = cv2.split(image_hsv)
            channel_names = ['Hue', 'Saturation', 'Value']
        elif color_space == 'HSI':
            # BGR to HSI (ê·¼ì‚¬ê°’)
            image_hsi = self.bgr_to_hsi(image)
            channels = cv2.split(image_hsi)
            channel_names = ['Hue', 'Saturation', 'Intensity']
        
        self.progress.emit(50)
        
        # ê° ì±„ë„ì„ ë³„ë„ íŒŒì¼ë¡œ ì €ì¥
        base_path = Path(self.output_path)
        base_name = base_path.stem
        base_dir = base_path.parent
        
        saved_files = []
        for i, (channel, name) in enumerate(zip(channels, channel_names)):
            channel_path = base_dir / f"{base_name}_{name}.png"
            cv2.imwrite(str(channel_path), channel)
            saved_files.append(str(channel_path))
            self.progress.emit(50 + (i + 1) * 15)
        
        self.progress.emit(100)
        message = f"{color_space} ì±„ë„ ë¶„ë¦¬ ì™„ë£Œ\nì €ì¥ëœ íŒŒì¼ë“¤:\n" + "\n".join(saved_files)
        self.result.emit(message, str(saved_files[0]))
    
    def convert_color_domain(self):
        """ìƒ‰ìƒ ë„ë©”ì¸ ë³€í™˜"""
        self.progress.emit(20)
        
        image = cv2.imread(self.input_path)
        if image is None:
            raise ValueError("ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        source_domain = self.parameters.get('source', 'BGR')
        target_domain = self.parameters.get('target', 'HSV')
        
        self.progress.emit(50)
        
        # ìƒ‰ìƒ ê³µê°„ ë³€í™˜
        if source_domain == 'BGR' and target_domain == 'HSV':
            converted = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        elif source_domain == 'BGR' and target_domain == 'RGB':
            converted = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        elif source_domain == 'BGR' and target_domain == 'LAB':
            converted = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        elif source_domain == 'BGR' and target_domain == 'GRAY':
            converted = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        elif source_domain == 'BGR' and target_domain == 'HSI':
            converted = self.bgr_to_hsi(image)
        else:
            converted = image
        
        self.progress.emit(80)
        
        # ì €ì¥
        cv2.imwrite(self.output_path, converted)
        
        self.progress.emit(100)
        message = f"ìƒ‰ìƒ ë„ë©”ì¸ ë³€í™˜ ì™„ë£Œ: {source_domain} â†’ {target_domain}"
        self.result.emit(message, self.output_path)
    
    def generate_histogram(self):
        """íˆìŠ¤í† ê·¸ë¨ ìƒì„±"""
        self.progress.emit(20)
        
        image = cv2.imread(self.input_path)
        if image is None:
            raise ValueError("ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # RGBë¡œ ë³€í™˜
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        self.progress.emit(50)
        
        # íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle('Image Histogram Analysis')
        
        # ì›ë³¸ ì´ë¯¸ì§€ í‘œì‹œ
        axes[0, 0].imshow(image_rgb)
        axes[0, 0].set_title('Original Image')
        axes[0, 0].axis('off')
        
        # RGB íˆìŠ¤í† ê·¸ë¨
        colors = ['red', 'green', 'blue']
        for i, color in enumerate(colors):
            hist = cv2.calcHist([image_rgb], [i], None, [256], [0, 256])
            axes[0, 1].plot(hist, color=color, alpha=0.7, label=f'{color.capitalize()} channel')
        axes[0, 1].set_title('RGB Histogram')
        axes[0, 1].set_xlabel('Pixel Value')
        axes[0, 1].set_ylabel('Frequency')
        axes[0, 1].legend()
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ íˆìŠ¤í† ê·¸ë¨
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        hist_gray = cv2.calcHist([gray], [0], None, [256], [0, 256])
        axes[1, 0].plot(hist_gray, color='black')
        axes[1, 0].set_title('Grayscale Histogram')
        axes[1, 0].set_xlabel('Pixel Value')
        axes[1, 0].set_ylabel('Frequency')
        
        # HSV íˆìŠ¤í† ê·¸ë¨
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        hist_h = cv2.calcHist([hsv], [0], None, [180], [0, 180])
        axes[1, 1].plot(hist_h, color='purple')
        axes[1, 1].set_title('Hue Histogram')
        axes[1, 1].set_xlabel('Hue Value')
        axes[1, 1].set_ylabel('Frequency')
        
        self.progress.emit(80)
        
        # íˆìŠ¤í† ê·¸ë¨ ì €ì¥
        plt.tight_layout()
        plt.savefig(self.output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.progress.emit(100)
        message = f"íˆìŠ¤í† ê·¸ë¨ ë¶„ì„ ì™„ë£Œ"
        self.result.emit(message, self.output_path)
    
    def enhance_image(self):
        """ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ"""
        self.progress.emit(20)
        
        # PILë¡œ ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(self.input_path)
        
        brightness = self.parameters.get('brightness', 1.0)
        contrast = self.parameters.get('contrast', 1.0)
        saturation = self.parameters.get('saturation', 1.0)
        sharpness = self.parameters.get('sharpness', 1.0)
        
        self.progress.emit(40)
        
        # ê° ì†ì„± ì¡°ì •
        if brightness != 1.0:
            enhancer = ImageEnhance.Brightness(image)
            image = enhancer.enhance(brightness)
        
        if contrast != 1.0:
            enhancer = ImageEnhance.Contrast(image)
            image = enhancer.enhance(contrast)
        
        self.progress.emit(60)
        
        if saturation != 1.0:
            enhancer = ImageEnhance.Color(image)
            image = enhancer.enhance(saturation)
        
        if sharpness != 1.0:
            enhancer = ImageEnhance.Sharpness(image)
            image = enhancer.enhance(sharpness)
        
        self.progress.emit(80)
        
        # ì €ì¥
        image.save(self.output_path)
        
        self.progress.emit(100)
        message = f"ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ ì™„ë£Œ"
        self.result.emit(message, self.output_path)
    
    def apply_filter(self):
        """í•„í„° ì ìš©"""
        self.progress.emit(20)
        
        image = cv2.imread(self.input_path)
        if image is None:
            raise ValueError("ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        filter_type = self.parameters.get('filter_type', 'blur')
        kernel_size = self.parameters.get('kernel_size', 5)
        
        self.progress.emit(50)
        
        if filter_type == 'blur':
            result = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
        elif filter_type == 'sharpen':
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            result = cv2.filter2D(image, -1, kernel)
        elif filter_type == 'edge':
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            result = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
        elif filter_type == 'emboss':
            kernel = np.array([[-2,-1,0], [-1,1,1], [0,1,2]])
            result = cv2.filter2D(image, -1, kernel)
        else:
            result = image
        
        self.progress.emit(80)
        
        cv2.imwrite(self.output_path, result)
        
        self.progress.emit(100)
        message = f"{filter_type} í•„í„° ì ìš© ì™„ë£Œ"
        self.result.emit(message, self.output_path)
    
    def crop_video(self):
        """ë¹„ë””ì˜¤ ìë¥´ê¸° (ì‹œê°„ ë²”ìœ„)"""
        import ffmpeg
        
        self.progress.emit(20)
        
        start_time = self.parameters.get('start_time', 0)  # ì´ˆ
        duration = self.parameters.get('duration', 10)     # ì´ˆ
        
        self.progress.emit(50)
        
        try:
            (
                ffmpeg
                .input(self.input_path, ss=start_time, t=duration)
                .output(self.output_path)
                .overwrite_output()
                .run(capture_stdout=True, capture_stderr=True)
            )
        except ffmpeg.Error as e:
            raise Exception(f"FFmpeg ì˜¤ë¥˜: {e.stderr.decode()}")
        
        self.progress.emit(100)
        message = f"ë¹„ë””ì˜¤ ìë¥´ê¸° ì™„ë£Œ: {start_time}ì´ˆë¶€í„° {duration}ì´ˆê°„"
        self.result.emit(message, self.output_path)
    
    def upscale_image(self):
        """ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§"""
        self.progress.emit(20)
        
        image = cv2.imread(self.input_path)
        if image is None:
            raise ValueError("ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        scale_factor = self.parameters.get('scale_factor', 2)
        method = self.parameters.get('method', 'INTER_CUBIC')
        
        self.progress.emit(50)
        
        # ì—…ìŠ¤ì¼€ì¼ë§ ë°©ë²•
        if method == 'INTER_LINEAR':
            interpolation = cv2.INTER_LINEAR
        elif method == 'INTER_CUBIC':
            interpolation = cv2.INTER_CUBIC
        elif method == 'INTER_LANCZOS4':
            interpolation = cv2.INTER_LANCZOS4
        else:
            interpolation = cv2.INTER_CUBIC
        
        # ìƒˆ í¬ê¸° ê³„ì‚°
        height, width = image.shape[:2]
        new_width = int(width * scale_factor)
        new_height = int(height * scale_factor)
        
        self.progress.emit(70)
        
        # ì—…ìŠ¤ì¼€ì¼ë§ ìˆ˜í–‰
        upscaled = cv2.resize(image, (new_width, new_height), interpolation=interpolation)
        
        self.progress.emit(90)
        
        cv2.imwrite(self.output_path, upscaled)
        
        self.progress.emit(100)
        message = f"ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ: {width}x{height} â†’ {new_width}x{new_height}"
        self.result.emit(message, self.output_path)
    
    def reduce_noise(self):
        """ë…¸ì´ì¦ˆ ê°ì†Œ"""
        self.progress.emit(20)
        
        image = cv2.imread(self.input_path)
        if image is None:
            raise ValueError("ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        method = self.parameters.get('method', 'bilateral')
        strength = self.parameters.get('strength', 10)
        
        self.progress.emit(50)
        
        if method == 'bilateral':
            result = cv2.bilateralFilter(image, 9, strength * 2, strength * 2)
        elif method == 'gaussian':
            result = cv2.GaussianBlur(image, (5, 5), strength / 10)
        elif method == 'median':
            result = cv2.medianBlur(image, min(strength, 15))
        elif method == 'nlmeans':
            result = cv2.fastNlMeansDenoisingColored(image, None, strength, strength, 7, 21)
        else:
            result = image
        
        self.progress.emit(80)
        
        cv2.imwrite(self.output_path, result)
        
        self.progress.emit(100)
        message = f"{method} ë…¸ì´ì¦ˆ ê°ì†Œ ì™„ë£Œ"
        self.result.emit(message, self.output_path)
    
    def bgr_to_hsi(self, image):
        """BGRì„ HSIë¡œ ë³€í™˜ (ê·¼ì‚¬ê°’)"""
        # BGRì„ RGBë¡œ ë³€í™˜
        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        rgb = rgb.astype(np.float32) / 255.0
        
        # HSI ê³„ì‚°
        r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]
        
        # Intensity
        i = (r + g + b) / 3.0
        
        # Saturation
        min_rgb = np.minimum(np.minimum(r, g), b)
        s = 1 - (3 * min_rgb) / (r + g + b + 1e-6)
        
        # Hue
        numerator = 0.5 * ((r - g) + (r - b))
        denominator = np.sqrt((r - g)**2 + (r - b) * (g - b)) + 1e-6
        h = np.arccos(np.clip(numerator / denominator, -1, 1))
        h[b > g] = 2 * np.pi - h[b > g]
        h = h / (2 * np.pi)
        
        # HSIë¥¼ 0-255 ë²”ìœ„ë¡œ ë³€í™˜
        hsi = np.stack([h * 255, s * 255, i * 255], axis=2)
        return hsi.astype(np.uint8)


class AdvancedProcessingDialog(QDialog):
    """ê³ ê¸‰ ì²˜ë¦¬ ë‹¤ì´ì–¼ë¡œê·¸"""
    
    def __init__(self, parent=None, file_path=None):
        super().__init__(parent)
        self.file_path = file_path
        self.processor = None
        
        self.setWindowTitle("ê³ ê¸‰ ì˜ìƒ/ì´ë¯¸ì§€ ì²˜ë¦¬")
        self.setMinimumSize(700, 600)
        
        self.setup_ui()
    
    def setup_ui(self):
        layout = QVBoxLayout(self)
        
        # íŒŒì¼ ì„ íƒ
        file_group = QGroupBox("ì…ë ¥ íŒŒì¼")
        file_layout = QHBoxLayout(file_group)
        
        self.file_label = QLabel("íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•ŠìŒ")
        if self.file_path:
            self.file_label.setText(str(Path(self.file_path).name))
        
        self.select_file_btn = QPushButton("íŒŒì¼ ì„ íƒ")
        self.select_file_btn.clicked.connect(self.select_file)
        
        file_layout.addWidget(self.file_label)
        file_layout.addWidget(self.select_file_btn)
        layout.addWidget(file_group)
        
        # ì²˜ë¦¬ ì˜µì…˜ íƒ­
        self.tab_widget = QTabWidget()
        
        # ì±„ë„ ë¶„ë¦¬ íƒ­
        self.create_channel_split_tab()
        
        # ìƒ‰ìƒ ë³€í™˜ íƒ­
        self.create_color_convert_tab()
        
        # ì´ë¯¸ì§€ í–¥ìƒ íƒ­
        self.create_enhance_tab()
        
        # í•„í„° íƒ­
        self.create_filter_tab()
        
        # ë¹„ë””ì˜¤ í¸ì§‘ íƒ­
        self.create_video_edit_tab()
        
        # ë¶„ì„ íƒ­
        self.create_analysis_tab()
        
        layout.addWidget(self.tab_widget)
        
        # ì²˜ë¦¬ ë²„íŠ¼
        self.process_btn = QPushButton("ì²˜ë¦¬ ì‹œì‘")
        self.process_btn.clicked.connect(self.start_processing)
        self.process_btn.setStyleSheet("""
            QPushButton {
                background-color: #2196F3;
                color: white;
                border: none;
                padding: 10px;
                font-size: 14px;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #1976D2;
            }
            QPushButton:disabled {
                background-color: #cccccc;
            }
        """)
        layout.addWidget(self.process_btn)
        
        # ì§„í–‰ë¥ 
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        layout.addWidget(self.progress_bar)
        
        # ê²°ê³¼ í‘œì‹œ
        self.result_text = QTextEdit()
        self.result_text.setMaximumHeight(100)
        self.result_text.setReadOnly(True)
        layout.addWidget(self.result_text)
        
        # ë‹«ê¸° ë²„íŠ¼
        close_btn = QPushButton("ë‹«ê¸°")
        close_btn.clicked.connect(self.close)
        layout.addWidget(close_btn)
    
    def create_channel_split_tab(self):
        """ì±„ë„ ë¶„ë¦¬ íƒ­ ìƒì„±"""
        tab = QWidget()
        layout = QVBoxLayout(tab)
        
        layout.addWidget(QLabel("ì»¬ëŸ¬ ì±„ë„ì„ ë¶„ë¦¬í•˜ì—¬ ê°ê°ì˜ ì´ë¯¸ì§€ë¡œ ì €ì¥í•©ë‹ˆë‹¤."))
        
        # ìƒ‰ìƒ ê³µê°„ ì„ íƒ
        color_group = QGroupBox("ìƒ‰ìƒ ê³µê°„")
        color_layout = QGridLayout(color_group)
        
        self.channel_color_combo = QComboBox()
        self.channel_color_combo.addItems(["RGB", "HSV", "HSI"])
        color_layout.addWidget(QLabel("ìƒ‰ìƒ ê³µê°„:"), 0, 0)
        color_layout.addWidget(self.channel_color_combo, 0, 1)
        
        layout.addWidget(color_group)
        layout.addStretch()
        
        self.tab_widget.addTab(tab, "ì±„ë„ ë¶„ë¦¬")
    
    def create_color_convert_tab(self):
        """ìƒ‰ìƒ ë³€í™˜ íƒ­ ìƒì„±"""
        tab = QWidget()
        layout = QVBoxLayout(tab)
        
        layout.addWidget(QLabel("ìƒ‰ìƒ ë„ë©”ì¸ì„ ë³€í™˜í•©ë‹ˆë‹¤."))
        
        convert_group = QGroupBox("ë³€í™˜ ì„¤ì •")
        convert_layout = QGridLayout(convert_group)
        
        # ì†ŒìŠ¤ ìƒ‰ìƒ ê³µê°„
        convert_layout.addWidget(QLabel("ì†ŒìŠ¤:"), 0, 0)
        self.source_combo = QComboBox()
        self.source_combo.addItems(["BGR", "RGB", "HSV", "LAB"])
        convert_layout.addWidget(self.source_combo, 0, 1)
        
        # íƒ€ê²Ÿ ìƒ‰ìƒ ê³µê°„
        convert_layout.addWidget(QLabel("íƒ€ê²Ÿ:"), 1, 0)
        self.target_combo = QComboBox()
        self.target_combo.addItems(["HSV", "RGB", "LAB", "GRAY", "HSI"])
        convert_layout.addWidget(self.target_combo, 1, 1)
        
        layout.addWidget(convert_group)
        layout.addStretch()
        
        self.tab_widget.addTab(tab, "ìƒ‰ìƒ ë³€í™˜")
    
    def create_enhance_tab(self):
        """ì´ë¯¸ì§€ í–¥ìƒ íƒ­ ìƒì„±"""
        tab = QWidget()
        layout = QVBoxLayout(tab)
        
        layout.addWidget(QLabel("ì´ë¯¸ì§€ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤."))
        
        enhance_group = QGroupBox("í–¥ìƒ ì„¤ì •")
        enhance_layout = QGridLayout(enhance_group)
        
        # ë°ê¸°
        enhance_layout.addWidget(QLabel("ë°ê¸°:"), 0, 0)
        self.brightness_slider = QSlider(Qt.Horizontal)
        self.brightness_slider.setRange(0, 200)
        self.brightness_slider.setValue(100)
        self.brightness_label = QLabel("1.0")
        self.brightness_slider.valueChanged.connect(
            lambda v: self.brightness_label.setText(f"{v/100:.1f}")
        )
        enhance_layout.addWidget(self.brightness_slider, 0, 1)
        enhance_layout.addWidget(self.brightness_label, 0, 2)
        
        # ëŒ€ë¹„
        enhance_layout.addWidget(QLabel("ëŒ€ë¹„:"), 1, 0)
        self.contrast_slider = QSlider(Qt.Horizontal)
        self.contrast_slider.setRange(0, 200)
        self.contrast_slider.setValue(100)
        self.contrast_label = QLabel("1.0")
        self.contrast_slider.valueChanged.connect(
            lambda v: self.contrast_label.setText(f"{v/100:.1f}")
        )
        enhance_layout.addWidget(self.contrast_slider, 1, 1)
        enhance_layout.addWidget(self.contrast_label, 1, 2)
        
        # ì±„ë„
        enhance_layout.addWidget(QLabel("ì±„ë„:"), 2, 0)
        self.saturation_slider = QSlider(Qt.Horizontal)
        self.saturation_slider.setRange(0, 200)
        self.saturation_slider.setValue(100)
        self.saturation_label = QLabel("1.0")
        self.saturation_slider.valueChanged.connect(
            lambda v: self.saturation_label.setText(f"{v/100:.1f}")
        )
        enhance_layout.addWidget(self.saturation_slider, 2, 1)
        enhance_layout.addWidget(self.saturation_label, 2, 2)
        
        # ì„ ëª…ë„
        enhance_layout.addWidget(QLabel("ì„ ëª…ë„:"), 3, 0)
        self.sharpness_slider = QSlider(Qt.Horizontal)
        self.sharpness_slider.setRange(0, 200)
        self.sharpness_slider.setValue(100)
        self.sharpness_label = QLabel("1.0")
        self.sharpness_slider.valueChanged.connect(
            lambda v: self.sharpness_label.setText(f"{v/100:.1f}")
        )
        enhance_layout.addWidget(self.sharpness_slider, 3, 1)
        enhance_layout.addWidget(self.sharpness_label, 3, 2)
        
        layout.addWidget(enhance_group)
        layout.addStretch()
        
        self.tab_widget.addTab(tab, "ì´ë¯¸ì§€ í–¥ìƒ")
    
    def create_filter_tab(self):
        """í•„í„° íƒ­ ìƒì„±"""
        tab = QWidget()
        layout = QVBoxLayout(tab)
        
        layout.addWidget(QLabel("ë‹¤ì–‘í•œ í•„í„°ë¥¼ ì ìš©í•©ë‹ˆë‹¤."))
        
        filter_group = QGroupBox("í•„í„° ì„¤ì •")
        filter_layout = QGridLayout(filter_group)
        
        # í•„í„° ì¢…ë¥˜
        filter_layout.addWidget(QLabel("í•„í„° ì¢…ë¥˜:"), 0, 0)
        self.filter_combo = QComboBox()
        self.filter_combo.addItems(["blur", "sharpen", "edge", "emboss"])
        filter_layout.addWidget(self.filter_combo, 0, 1)
        
        # ì»¤ë„ í¬ê¸° (ë¸”ëŸ¬ìš©)
        filter_layout.addWidget(QLabel("ê°•ë„:"), 1, 0)
        self.kernel_size_spin = QSpinBox()
        self.kernel_size_spin.setRange(3, 15)
        self.kernel_size_spin.setValue(5)
        self.kernel_size_spin.setSingleStep(2)  # í™€ìˆ˜ë§Œ
        filter_layout.addWidget(self.kernel_size_spin, 1, 1)
        
        layout.addWidget(filter_group)
        layout.addStretch()
        
        self.tab_widget.addTab(tab, "í•„í„°")
    
    def create_video_edit_tab(self):
        """ë¹„ë””ì˜¤ í¸ì§‘ íƒ­ ìƒì„±"""
        tab = QWidget()
        layout = QVBoxLayout(tab)
        
        layout.addWidget(QLabel("ë¹„ë””ì˜¤ë¥¼ ì‹œê°„ ë²”ìœ„ë¡œ ìë¦…ë‹ˆë‹¤."))
        
        video_group = QGroupBox("ìë¥´ê¸° ì„¤ì •")
        video_layout = QGridLayout(video_group)
        
        # ì‹œì‘ ì‹œê°„
        video_layout.addWidget(QLabel("ì‹œì‘ ì‹œê°„ (ì´ˆ):"), 0, 0)
        self.start_time_spin = QSpinBox()
        self.start_time_spin.setRange(0, 3600)
        self.start_time_spin.setValue(0)
        video_layout.addWidget(self.start_time_spin, 0, 1)
        
        # ì§€ì† ì‹œê°„
        video_layout.addWidget(QLabel("ì§€ì† ì‹œê°„ (ì´ˆ):"), 1, 0)
        self.duration_spin = QSpinBox()
        self.duration_spin.setRange(1, 3600)
        self.duration_spin.setValue(10)
        video_layout.addWidget(self.duration_spin, 1, 1)
        
        layout.addWidget(video_group)
        layout.addStretch()
        
        self.tab_widget.addTab(tab, "ë¹„ë””ì˜¤ í¸ì§‘")
    
    def create_analysis_tab(self):
        """ë¶„ì„ íƒ­ ìƒì„±"""
        tab = QWidget()
        layout = QVBoxLayout(tab)
        
        layout.addWidget(QLabel("ì´ë¯¸ì§€ ë¶„ì„ ë° íˆìŠ¤í† ê·¸ë¨ì„ ìƒì„±í•©ë‹ˆë‹¤."))
        
        analysis_group = QGroupBox("ë¶„ì„ ì˜µì…˜")
        analysis_layout = QVBoxLayout(analysis_group)
        
        self.histogram_check = QCheckBox("íˆìŠ¤í† ê·¸ë¨ ìƒì„±")
        self.histogram_check.setChecked(True)
        analysis_layout.addWidget(self.histogram_check)
        
        self.metadata_check = QCheckBox("ë©”íƒ€ë°ì´í„° ì¶”ì¶œ")
        analysis_layout.addWidget(self.metadata_check)
        
        self.color_analysis_check = QCheckBox("ìƒ‰ìƒ ë¶„í¬ ë¶„ì„")
        analysis_layout.addWidget(self.color_analysis_check)
        
        layout.addWidget(analysis_group)
        
        # ì—…ìŠ¤ì¼€ì¼ë§ ì˜µì…˜
        upscale_group = QGroupBox("ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§")
        upscale_layout = QGridLayout(upscale_group)
        
        upscale_layout.addWidget(QLabel("ë°°ìœ¨:"), 0, 0)
        self.scale_spin = QSpinBox()
        self.scale_spin.setRange(2, 8)
        self.scale_spin.setValue(2)
        upscale_layout.addWidget(self.scale_spin, 0, 1)
        
        upscale_layout.addWidget(QLabel("ë°©ë²•:"), 1, 0)
        self.upscale_method_combo = QComboBox()
        self.upscale_method_combo.addItems(["INTER_CUBIC", "INTER_LINEAR", "INTER_LANCZOS4"])
        upscale_layout.addWidget(self.upscale_method_combo, 1, 1)
        
        layout.addWidget(upscale_group)
        
        # ë…¸ì´ì¦ˆ ê°ì†Œ
        noise_group = QGroupBox("ë…¸ì´ì¦ˆ ê°ì†Œ")
        noise_layout = QGridLayout(noise_group)
        
        noise_layout.addWidget(QLabel("ë°©ë²•:"), 0, 0)
        self.noise_method_combo = QComboBox()
        self.noise_method_combo.addItems(["bilateral", "gaussian", "median", "nlmeans"])
        noise_layout.addWidget(self.noise_method_combo, 0, 1)
        
        noise_layout.addWidget(QLabel("ê°•ë„:"), 1, 0)
        self.noise_strength_spin = QSpinBox()
        self.noise_strength_spin.setRange(1, 50)
        self.noise_strength_spin.setValue(10)
        noise_layout.addWidget(self.noise_strength_spin, 1, 1)
        
        layout.addWidget(noise_group)
        layout.addStretch()
        
        self.tab_widget.addTab(tab, "ë¶„ì„/í–¥ìƒ")
    
    def select_file(self):
        """íŒŒì¼ ì„ íƒ"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "íŒŒì¼ ì„ íƒ", "",
            "ë¯¸ë””ì–´ íŒŒì¼ (*.jpg *.jpeg *.png *.bmp *.mp4 *.avi *.mov *.mkv);;ëª¨ë“  íŒŒì¼ (*)"
        )
        
        if file_path:
            self.file_path = file_path
            self.file_label.setText(Path(file_path).name)
    
    def start_processing(self):
        """ì²˜ë¦¬ ì‹œì‘"""
        if not self.file_path or not Path(self.file_path).exists():
            QMessageBox.warning(self, "ê²½ê³ ", "ìœ íš¨í•œ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")
            return
        
        # í˜„ì¬ íƒ­ì— ë”°ë¼ ì‘ì—… ê²°ì •
        current_tab_index = self.tab_widget.currentIndex()
        tab_names = ["channel_split", "domain_convert", "enhance", "filter", "crop_video", "analysis"]
        operation = tab_names[current_tab_index]
        
        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì •
        input_path = Path(self.file_path)
        if operation == "analysis":
            output_path = input_path.parent / f"{input_path.stem}_analysis.png"
        else:
            output_path = input_path.parent / f"{input_path.stem}_processed{input_path.suffix}"
        
        # íŒŒë¼ë¯¸í„° ìˆ˜ì§‘
        parameters = self.collect_parameters(operation)
        
        # ì²˜ë¦¬ ì‹œì‘
        self.process_btn.setEnabled(False)
        self.progress_bar.setVisible(True)
        self.progress_bar.setValue(0)
        self.result_text.clear()
        
        self.processor = AdvancedProcessor(
            str(self.file_path), str(output_path), operation, parameters
        )
        self.processor.progress.connect(self.progress_bar.setValue)
        self.processor.result.connect(self.on_processing_finished)
        self.processor.error.connect(self.on_processing_error)
        self.processor.start()
    
    def collect_parameters(self, operation):
        """ì‘ì—…ë³„ íŒŒë¼ë¯¸í„° ìˆ˜ì§‘"""
        parameters = {}
        
        if operation == "channel_split":
            parameters['color_space'] = self.channel_color_combo.currentText()
        
        elif operation == "domain_convert":
            parameters['source'] = self.source_combo.currentText()
            parameters['target'] = self.target_combo.currentText()
        
        elif operation == "enhance":
            parameters['brightness'] = self.brightness_slider.value() / 100.0
            parameters['contrast'] = self.contrast_slider.value() / 100.0
            parameters['saturation'] = self.saturation_slider.value() / 100.0
            parameters['sharpness'] = self.sharpness_slider.value() / 100.0
        
        elif operation == "filter":
            parameters['filter_type'] = self.filter_combo.currentText()
            parameters['kernel_size'] = self.kernel_size_spin.value()
        
        elif operation == "crop_video":
            parameters['start_time'] = self.start_time_spin.value()
            parameters['duration'] = self.duration_spin.value()
        
        elif operation == "analysis":
            # í˜„ì¬ëŠ” íˆìŠ¤í† ê·¸ë¨ë§Œ êµ¬í˜„
            parameters['histogram'] = self.histogram_check.isChecked()
            # ë‹¤ë¥¸ ë¶„ì„ ì˜µì…˜ë„ ì¶”ê°€í•  ìˆ˜ ìˆìŒ
            
            # ì—…ìŠ¤ì¼€ì¼ë§ íŒŒë¼ë¯¸í„°ë„ í¬í•¨
            parameters['scale_factor'] = self.scale_spin.value()
            parameters['upscale_method'] = self.upscale_method_combo.currentText()
            
            # ë…¸ì´ì¦ˆ ê°ì†Œ íŒŒë¼ë¯¸í„°
            parameters['noise_method'] = self.noise_method_combo.currentText()
            parameters['noise_strength'] = self.noise_strength_spin.value()
        
        return parameters
    
    def on_processing_finished(self, message, output_path):
        """ì²˜ë¦¬ ì™„ë£Œ"""
        self.progress_bar.setVisible(False)
        self.process_btn.setEnabled(True)
        self.result_text.append(f"âœ… {message}")
        self.result_text.append(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_path}")
        
        # ê²°ê³¼ íŒŒì¼ ì—´ê¸° ì˜µì…˜
        reply = QMessageBox.question(
            self, "ì²˜ë¦¬ ì™„ë£Œ", 
            f"{message}\n\nê²°ê³¼ íŒŒì¼ì„ ì—´ì–´ë³´ì‹œê² ìŠµë‹ˆê¹Œ?",
            QMessageBox.Yes | QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            import os
            os.startfile(output_path)  # Windows
    
    def on_processing_error(self, error):
        """ì²˜ë¦¬ ì˜¤ë¥˜"""
        self.progress_bar.setVisible(False)
        self.process_btn.setEnabled(True)
        self.result_text.append(f"âŒ ì˜¤ë¥˜: {error}")
        QMessageBox.critical(self, "ì˜¤ë¥˜", error)